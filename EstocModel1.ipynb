{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def metrica_avaliacao(df, predict_column='risk_index',\n",
    "                      viaturas=3, number_random_executions=1): \n",
    "    sum_true = 0\n",
    "    sum_pred = 0\n",
    "    for month in df.month_number.unique():\n",
    "        df_m = df[df.month_number==month]\n",
    "        for dia in df_m.dia.unique():\n",
    "            df_d = df_m[df_m.dia==dia]\n",
    "            for p in df_d.periodo.unique():\n",
    "                df_p_real = df_d[df_d.periodo == p].copy()\n",
    "                df_p_pred = df_p_real.copy()\n",
    "                \n",
    "                sum_true += df_p_real.sort_values(\n",
    "                    by='acidentes_graves', ascending=False)['acidentes_graves'][:viaturas].sum()\n",
    "                sum_pred += df_p_pred.sort_values(\n",
    "                    by=predict_column, ascending=False)['acidentes_graves'][:viaturas].sum()\n",
    "                \n",
    "    return sum_true, sum_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     1,
     10,
     27,
     36,
     45,
     70,
     78,
     97,
     159
    ]
   },
   "outputs": [],
   "source": [
    "class WeightedProb:\n",
    "    def __init__(self, df, side_var_columns, train_til_year):\n",
    "        \n",
    "        self.df = df\n",
    "        self.side_var_columns = side_var_columns\n",
    "        self.train_til_year = train_til_year\n",
    "        \n",
    "        # inicializando os pesos\n",
    "        self.best_opt_weights = np.ones(len(side_var_columns))\n",
    "    \n",
    "    def get_mes_dia_mais_proximo(self, df_recorte, mes_in, dia_in, periodo_in):\n",
    "        meses = df_recorte.month_number.unique()\n",
    "        \n",
    "        if len(meses)>0:\n",
    "            mes_mais_prox = meses[np.argmin(np.abs(np.array(meses) - mes_in))]\n",
    "        \n",
    "            dias = df_recorte[(df_recorte['month_number']==mes_mais_prox)].dia.unique()\n",
    "            dia_mais_prox = dias[np.argmin(np.abs(np.array(dias) - dia_in))]\n",
    "\n",
    "            periodos = df_recorte[(df_recorte['month_number']==mes_mais_prox) &(df_recorte['dia']==dia_in)].periodo.unique()\n",
    "            \n",
    "            condition = (mes_mais_prox == mes_in) and (dia_mais_prox == dia_in) and (periodo_in in periodos)\n",
    "        else:\n",
    "            condition = False\n",
    "              \n",
    "        return condition \n",
    "    \n",
    "    def func_risk_index(self, dict_side_var_columns_probs, x):\n",
    "        risk=0\n",
    "        for i, sv in enumerate(self.side_var_columns):\n",
    "            try:\n",
    "                risk += dict_side_var_columns_probs[sv][x[sv]]*self.best_opt_weights[i]\n",
    "            except:\n",
    "                pass\n",
    "        return risk\n",
    "    \n",
    "    def func_risco_otimizando(self, dict_side_var_columns_probs, x):\n",
    "        risk=0\n",
    "        for i, sv in enumerate(self.side_var_columns):\n",
    "            try:\n",
    "                risk += dict_side_var_columns_probs[sv][x[sv]]*self.pop_opt_weights[i]\n",
    "            except:\n",
    "                pass\n",
    "        return risk\n",
    "    \n",
    "    def fit(self):\n",
    "\n",
    "        self.df_train = self.df[(self.df['ano'] <= self.train_til_year)]\n",
    "        \n",
    "        self.dict_side_var_columns_probs = {}\n",
    "\n",
    "        for sv in self.side_var_columns:\n",
    "            dict_uniques_sv_prob = {}\n",
    "            for u in self.df_train[sv].unique():\n",
    "                dict_uniques_sv_prob[u] = self.df_train[\n",
    "                    (self.df_train[sv]==u) & (\n",
    "                        self.df_train.acidentes_graves==1)].count(\n",
    "                ).values[0]/self.df_train[(self.df_train[sv]==u)].count().values[0]\n",
    "\n",
    "            self.dict_side_var_columns_probs[sv] = dict_uniques_sv_prob\n",
    "\n",
    "        self.df_train['risk_index'] = self.df_train[self.side_var_columns].apply((\n",
    "            lambda x: self.func_risk_index(self.dict_side_var_columns_probs, x)), axis=1)                      \n",
    "\n",
    "        for sv in self.side_var_columns:\n",
    "            column_name_prob = sv + \"_prob\"            \n",
    "            self.df_train[column_name_prob] = self.df_train[sv].apply(lambda x: self.dict_side_var_columns_probs[sv][x]) \n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, df_in):\n",
    "        \n",
    "        self.df_out = df_in.copy()        \n",
    "        self.df_out['risk_index'] = self.df_out[self.side_var_columns].apply(\n",
    "            (lambda x: self.func_risk_index(self.dict_side_var_columns_probs, x)), axis=1)\n",
    "        \n",
    "        return self.df_out.copy()\n",
    "    \n",
    "    def metrica_avaliacao(self, df, predict_column='risk_index', real_column='acidentes_graves',\n",
    "                          viaturas=3):  \n",
    "        sum_true = 0\n",
    "        sum_pred = 0\n",
    "\n",
    "        for month in df.month_number.unique():\n",
    "            df_m = df[df.month_number==month]\n",
    "            for dia in df_m.dia.unique():\n",
    "                df_d = df_m[df_m.dia==dia]\n",
    "                for p in df_d.periodo.unique():\n",
    "                    df_p_real = df_d[df_d.periodo == p].copy()\n",
    "                    df_p_pred = df_p_real.copy()\n",
    "                    sum_true += df_p_real.sort_values(\n",
    "                        by=real_column, ascending=False)[real_column][:viaturas].sum()\n",
    "                    sum_pred += df_p_pred.sort_values(\n",
    "                        by=predict_column, ascending=False)[real_column][:viaturas].sum()\n",
    "\n",
    "        return sum_true, sum_pred\n",
    "\n",
    "    def optimize(self,\n",
    "                   df_objetivo,\n",
    "                   real_column=['mortos','feridos_graves'],\n",
    "                   predict_column='risco_otimizado',\n",
    "                   gama=0.5,\n",
    "                   viaturas=10,\n",
    "                   epochs=10,\n",
    "                   pop_size=100):\n",
    "        \n",
    "        df = self.predict(df_objetivo)\n",
    "        \n",
    "        best_sum_pred = 0\n",
    "        len_opt_weigths = len(self.best_opt_weights)\n",
    "        \n",
    "        sum_true, _ = self.metrica_avaliacao(df)\n",
    "\n",
    "        print('Objetivo:',sum_true)\n",
    "        \n",
    "        population = np.random.randn(pop_size,len_opt_weigths)\n",
    "        population[0,:] = self.best_opt_weights\n",
    "        fitness = np.zeros(pop_size)\n",
    "        \n",
    "        for z in range(epochs):\n",
    "            \n",
    "            for pop in range(population.shape[0]):\n",
    "                risco_otimizado = []\n",
    "                \n",
    "                self.pop_opt_weights = population[pop,:]\n",
    "\n",
    "                df[predict_column] = df[self.side_var_columns].apply((\n",
    "                                    lambda x: self.func_risco_otimizando(self.dict_side_var_columns_probs, x)), axis=1)  \n",
    "\n",
    "                _, sum_pred = self.metrica_avaliacao(df, predict_column=predict_column)\n",
    "                            \n",
    "                print(sum_true, sum_pred, pop)\n",
    "                fitness[pop] = (sum_true - sum_pred)\n",
    "            \n",
    "            best_fathers = population[fitness.argsort()][:int(population.shape[0]/2),:]\n",
    "            worst_fathers = population[fitness.argsort()][int(population.shape[0]/2):,:]\n",
    "            \n",
    "            for pop in range(population.shape[0]):\n",
    "                \n",
    "                if pop < 0.25*population.shape[0]:\n",
    "                    population[pop,:int(population.shape[1]*(population.shape[0]-pop)/population.shape[0])] = best_fathers[int(pop/2),:int(population.shape[1]*(population.shape[0]-pop)/population.shape[0])]\n",
    "                elif pop < 0.50*population.shape[0] and pop > 0.25*population.shape[0]:\n",
    "                    population[pop,:int(population.shape[1]*(population.shape[0]-pop)/population.shape[0])] = best_fathers[int(pop/2),:int(population.shape[1]*(population.shape[0]-pop)/population.shape[0])]\n",
    "                    population[pop,:] += np.random.randn(len_opt_weigths)\n",
    "                else:\n",
    "                    population[pop,:int(population.shape[1]*(population.shape[0]-pop)/population.shape[0])] = worst_fathers[int(pop/2),:int(population.shape[1]*(population.shape[0]-pop)/population.shape[0])]\n",
    "                    population[pop,:] += np.random.randn(len_opt_weigths)\n",
    "            \n",
    "            fitness.sort()\n",
    "            if fitness[0] < np.abs(sum_true - best_sum_pred):\n",
    "                best_sum_pred = sum_true - fitness[0]\n",
    "                best_opt_weights = best_fathers[0,:]\n",
    "            \n",
    "            print(best_sum_pred)\n",
    "            \n",
    "        self.best_opt_weights = best_opt_weights\n",
    "        \n",
    "        return sum_true, best_sum_pred\n",
    "    \n",
    "    def cross_val_lombra(self, year_test=[2016,2017,2018], caso='todos_no_GA'):\n",
    "        \n",
    "        self.cross_val_result = []\n",
    "        year_test = year_test\n",
    "        \n",
    "        for yt in year_test:\n",
    "            df_train = self.df[self.df.ano != yt]\n",
    "            df_test = self.df[self.df.ano == yt]\n",
    "            dict_side_var_columns_probs = {}\n",
    "            for sv in self.side_var_columns:\n",
    "                dict_uniques_sv_prob = {}\n",
    "                for u in df_train[sv].unique():\n",
    "                    dict_uniques_sv_prob[u] = df_train[\n",
    "                        (df_train[sv]==u) & (df_train.acidentes_graves==1)].count(\n",
    "                    ).values[0]/df_train[(df_train[sv]==u)].count().values[0]\n",
    "\n",
    "                dict_side_var_columns_probs[sv] = dict_uniques_sv_prob\n",
    "\n",
    "            df_train['risk_index'] = df_train[self.side_var_columns].apply((\n",
    "                lambda x: self.func_risk_index(dict_side_var_columns_probs, x)), axis=1)                      \n",
    "\n",
    "            for sv in self.side_var_columns:\n",
    "                column_name_prob = sv + \"_prob\"            \n",
    "                df_train[column_name_prob] = df_train[sv].apply(lambda x: dict_side_var_columns_probs[sv][x]) \n",
    "            \n",
    "            df_out = df_test.copy()        \n",
    "            df_out['risk_index'] = df_out[self.side_var_columns].apply(\n",
    "            (lambda x: self.func_risk_index(dict_side_var_columns_probs, x)), axis=1)\n",
    "            \n",
    "            sum_true, sum_pred = self.metrica_avaliacao(df_out)\n",
    "            \n",
    "            self.cross_val_result.append([yt, sum_true, sum_pred])\n",
    "            \n",
    "            df_out.to_csv('cross_val_lombra_wp/'+str(yt)+caso+'.csv', index=None)\n",
    "            \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a\n",
       "0  a\n",
       "1  a\n",
       "2  a\n",
       "3  a\n",
       "4  a\n",
       "5  a\n",
       "6  a\n",
       "7  a\n",
       "8  a\n",
       "9  a"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.DataFrame(columns=['a'])\n",
    "a.a = ['a']*10\n",
    "a.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ignorada' 'tempo_claro' 'tempo_adverso']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dia_semana</th>\n",
       "      <th>br</th>\n",
       "      <th>condicao_meteorologica</th>\n",
       "      <th>tipo_pista</th>\n",
       "      <th>tracado_via</th>\n",
       "      <th>uso_solo</th>\n",
       "      <th>mortos</th>\n",
       "      <th>feridos_leves</th>\n",
       "      <th>feridos_graves</th>\n",
       "      <th>ilesos</th>\n",
       "      <th>...</th>\n",
       "      <th>feridos</th>\n",
       "      <th>veiculos</th>\n",
       "      <th>feriado</th>\n",
       "      <th>km_bins</th>\n",
       "      <th>periodo</th>\n",
       "      <th>ano</th>\n",
       "      <th>month_number</th>\n",
       "      <th>dia</th>\n",
       "      <th>data</th>\n",
       "      <th>acidentes_graves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>terca</td>\n",
       "      <td>104</td>\n",
       "      <td>ignorada</td>\n",
       "      <td>dupla</td>\n",
       "      <td>reta</td>\n",
       "      <td>sim</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>not-feriado</td>\n",
       "      <td>[60, 65)</td>\n",
       "      <td>[8, 12)</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>terca</td>\n",
       "      <td>104</td>\n",
       "      <td>ignorada</td>\n",
       "      <td>dupla</td>\n",
       "      <td>reta</td>\n",
       "      <td>sim</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>not-feriado</td>\n",
       "      <td>[60, 65)</td>\n",
       "      <td>[16, 20)</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>terca</td>\n",
       "      <td>104</td>\n",
       "      <td>ignorada</td>\n",
       "      <td>dupla</td>\n",
       "      <td>reta</td>\n",
       "      <td>sim</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>not-feriado</td>\n",
       "      <td>[60, 65)</td>\n",
       "      <td>[20, 24)</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>terca</td>\n",
       "      <td>104</td>\n",
       "      <td>ignorada</td>\n",
       "      <td>dupla</td>\n",
       "      <td>reta</td>\n",
       "      <td>sim</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>not-feriado</td>\n",
       "      <td>[60, 65)</td>\n",
       "      <td>[12, 16)</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>terca</td>\n",
       "      <td>104</td>\n",
       "      <td>ignorada</td>\n",
       "      <td>dupla</td>\n",
       "      <td>reta</td>\n",
       "      <td>sim</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>not-feriado</td>\n",
       "      <td>[60, 65)</td>\n",
       "      <td>[4, 8)</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  dia_semana   br condicao_meteorologica tipo_pista tracado_via uso_solo  \\\n",
       "0      terca  104               ignorada      dupla        reta      sim   \n",
       "1      terca  104               ignorada      dupla        reta      sim   \n",
       "2      terca  104               ignorada      dupla        reta      sim   \n",
       "3      terca  104               ignorada      dupla        reta      sim   \n",
       "4      terca  104               ignorada      dupla        reta      sim   \n",
       "\n",
       "   mortos  feridos_leves  feridos_graves  ilesos  ...  feridos  veiculos  \\\n",
       "0       0              0               0       0  ...        0         0   \n",
       "1       0              0               0       0  ...        0         0   \n",
       "2       0              0               0       0  ...        0         0   \n",
       "3       0              0               0       0  ...        0         0   \n",
       "4       0              0               0       0  ...        0         0   \n",
       "\n",
       "       feriado   km_bins   periodo   ano  month_number  dia  \\\n",
       "0  not-feriado  [60, 65)   [8, 12)  2019             1    1   \n",
       "1  not-feriado  [60, 65)  [16, 20)  2019             1    1   \n",
       "2  not-feriado  [60, 65)  [20, 24)  2019             1    1   \n",
       "3  not-feriado  [60, 65)  [12, 16)  2019             1    1   \n",
       "4  not-feriado  [60, 65)    [4, 8)  2019             1    1   \n",
       "\n",
       "                  data acidentes_graves  \n",
       "0  2019-01-01 00:00:00                0  \n",
       "1  2019-01-01 00:00:00                0  \n",
       "2  2019-01-01 00:00:00                0  \n",
       "3  2019-01-01 00:00:00                0  \n",
       "4  2019-01-01 00:00:00                0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('df_19_18_17_16_pad.csv')\n",
    "\n",
    "print(df.condicao_meteorologica.unique())\n",
    "\n",
    "df.drop(['index','km'],axis=1, inplace=True)\n",
    "\n",
    "df['acidentes_graves'] = df['mortos'\n",
    "                                    ]+df['feridos_graves'\n",
    "                                    ]+df['feridos']\n",
    "#                                     ]+df['feridos_leves'\n",
    "#                                     ]+df['ilesos']\n",
    "\n",
    "df['acidentes_graves'] = df['acidentes_graves'].apply(lambda x: 1 if (x > 0) else 0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hugo\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Hugo\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.WeightedProb at 0x1cfaf212808>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# km_bins vai fazer o papel do main.\n",
    "side_var_columns = ['km_bins','br','tipo_pista', 'tracado_via', 'uso_solo','periodo', 'condicao_meteorologica',\n",
    "                    'feriado', 'dia_semana','month_number','dia']\n",
    "\n",
    "WPudo = WeightedProb(df, side_var_columns, train_til_year=2018)\n",
    "WPudo.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predicting for padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019 = df[df.ano==2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019_out = WPudo.predict(df_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(293, 145)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrica_avaliacao(df_2019_out, viaturas=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019_out.to_csv('cross_val_lombra_wp/2019sograve_no_GA.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hugo\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Hugo\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:183: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.WeightedProb at 0x14ceb0d2f88>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WPudo.cross_val_lombra(year_test=[2016, 2017, 2018], caso='sograve_no_GA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2016, 351, 144], [2017, 323, 151], [2018, 253, 123]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WPudo.cross_val_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WPudo.best_opt_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## otimizando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objetivo: 293\n",
      "293 145 0\n",
      "293 134 1\n",
      "293 1 2\n",
      "293 87 3\n",
      "293 48 4\n",
      "293 94 5\n",
      "293 84 6\n",
      "293 77 7\n",
      "293 101 8\n",
      "293 61 9\n",
      "293 35 10\n",
      "293 101 11\n",
      "293 140 12\n",
      "293 67 13\n",
      "293 108 14\n",
      "293 26 15\n",
      "293 57 16\n",
      "293 23 17\n",
      "293 81 18\n",
      "293 115 19\n",
      "145.0\n",
      "293 145 0\n",
      "293 145 1\n",
      "293 140 2\n",
      "293 140 3\n",
      "293 59 4\n",
      "293 120 5\n",
      "293 117 6\n",
      "293 104 7\n",
      "293 81 8\n",
      "293 89 9\n",
      "293 56 10\n",
      "293 112 11\n",
      "293 85 12\n",
      "293 140 13\n",
      "293 126 14\n",
      "293 52 15\n",
      "293 71 16\n",
      "293 31 17\n",
      "293 73 18\n",
      "293 41 19\n",
      "145.0\n",
      "293 145 0\n",
      "293 145 1\n",
      "293 145 2\n",
      "293 145 3\n",
      "293 68 4\n",
      "293 3 5\n",
      "293 76 6\n",
      "293 90 7\n",
      "293 109 8\n",
      "293 81 9\n",
      "293 70 10\n",
      "293 40 11\n",
      "293 127 12\n",
      "293 114 13\n",
      "293 135 14\n",
      "293 115 15\n",
      "293 69 16\n",
      "293 16 17\n",
      "293 77 18\n",
      "293 40 19\n",
      "145.0\n",
      "293 145 0\n",
      "293 145 1\n",
      "293 145 2\n",
      "293 145 3\n",
      "293 70 4\n",
      "293 6 5\n",
      "293 146 6\n",
      "293 140 7\n",
      "293 111 8\n",
      "293 126 9\n",
      "293 52 10\n",
      "293 0 11\n",
      "293 140 12\n",
      "293 110 13\n",
      "293 118 14\n",
      "293 114 15\n",
      "293 64 16\n",
      "293 22 17\n",
      "293 5 18\n",
      "293 113 19\n",
      "146.0\n",
      "293 146 0\n",
      "293 146 1\n",
      "293 145 2\n",
      "293 145 3\n",
      "293 70 4\n",
      "293 39 5\n",
      "293 133 6\n",
      "293 147 7\n",
      "293 90 8\n",
      "293 56 9\n",
      "293 55 10\n",
      "293 0 11\n",
      "293 22 12\n",
      "293 104 13\n",
      "293 41 14\n",
      "293 36 15\n",
      "293 63 16\n",
      "293 8 17\n",
      "293 2 18\n",
      "293 109 19\n",
      "147.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(293, 147.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WPudo.optimize(viaturas=3, df_objetivo=df_2019_out, pop_size=20, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019_opt = WPudo.predict(df_2019_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(293, 147)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrica_avaliacao(df_2019_opt, viaturas=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.66954849, -0.40323901,  1.82367703,  3.28080945,  1.06568867,\n",
       "        0.7110041 ,  1.96407835,  1.91126351,  5.63694876,  1.29987127,\n",
       "       -1.76266977])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WPudo.best_opt_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019_opt.to_csv('cross_val_lombra_wp/2019sograve_yes_GA.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hugo\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Hugo\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:183: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.WeightedProb at 0x14ceb0d2f88>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WPudo.cross_val_lombra(caso='sograve_yes_GA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2016, 351, 143], [2017, 323, 156], [2018, 253, 121]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WPudo.cross_val_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
